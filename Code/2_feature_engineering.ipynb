{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Feature Engineering\n",
    "\n",
    "According to [Wikipedia, Feature engineering](https://en.wikipedia.org/wiki/Feature_engineering) is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning, and is both difficult and expensive. \n",
    "\n",
    "This Feature engineering notebook will load the data sets created in the **Data Ingestion** notebook (`Code/1_data_ingestion.ipynb`) from an Azure storage container and combine them to create a single data set of features (variables) that can be used to infer a machines's health condition over time. The notebook steps through several feature engineering and labeling methods to create this data set for use in our predictive maintenance machine learning solution.\n",
    "\n",
    "**Note:** This notebook will take about 20-30 minutes to execute all cells, depending on the compute configuration you have setup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/ubuntu/PredictiveMaintenance/aml_config/PredictiveMaintenanceWSConfig.json\n"
     ]
    }
   ],
   "source": [
    "# Load workspace using configuration file \n",
    "ws = Workspace.from_config(path = '../aml_config/PredictiveMaintenanceWSConfig.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ingestion will be run within a separate experiment \n",
    "exp = Experiment(name = 'FeatureEngIneering', workspace = ws) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Run is created \n",
    "run = exp.start_logging() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can log any information we want \n",
    "import time\n",
    "run.log('Starting Feature Engineering', time.asctime(time.localtime(time.time()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.tag('Description', 'Feature Engineering') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Azure blob storage details here \n",
    "ACCOUNT_NAME = \"predictistorageinugjxfr\"\n",
    "\n",
    "# You can find the account key under the _Access Keys_ link in the \n",
    "# [Azure Portal](portal.azure.com) page for your Azure storage container.\n",
    "ACCOUNT_KEY = \"moQjKkXdNdA2xHGuPpC4YdxDeotmTkkm+Pa7zopIHcy1xNhVf5hvU+tO9OQLC3cxVG01IKvEZeSHAOEgmdrV1w==\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/ggplot/utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n"
     ]
    }
   ],
   "source": [
    "## Setup our environment by importing required libraries\n",
    "#import time\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Read csv file from URL directly\n",
    "import pandas as pd\n",
    "\n",
    "# For creating some preliminary EDA plots.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ggplot import *\n",
    "\n",
    "import datetime\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, unix_timestamp, round\n",
    "from pyspark.sql.functions import datediff\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# For Azure blob storage access\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess\n",
    "\n",
    "# For logging model evaluation parameters back into the\n",
    "# AML Workbench run history plots.\n",
    "#import logging\n",
    "#from azureml.logging import get_azureml_logger\n",
    "\n",
    "#amllog = logging.getLogger(\"azureml\")\n",
    "#amllog.level = logging.INFO\n",
    "\n",
    "# Turn on cell level logging.\n",
    "#%azureml history on\n",
    "#%azureml history show\n",
    "\n",
    "# Time the notebook execution. \n",
    "# This will only make sense if you \"Run all cells\"\n",
    "tic = time.time()\n",
    "\n",
    "#logger = get_azureml_logger() # logger writes to AMLWorkbench runtime view\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Telemetry\n",
    "#logger.log('amlrealworld.predictivemaintenance.feature_engineering','true') \n",
    "run.log('amlrealworld.predictivemaintenance.feature_engineering', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data from Azure Blob storage container\n",
    "\n",
    "In the **Data Ingestion** notebook (`Code/1_data_ingestion.ipynb`), we downloaded, converted and stored the following data sets into Azure blob storage:\n",
    "\n",
    "  * **Machines**: Features differentiating each machine. For example age and model.\n",
    "  * **Error**: The log of non-critical errors. These errors may still indicate an impending component failure.\n",
    "  * **Maint**: Machine maintenance history detailing component replacement or regular maintenance activities withe the date of replacement.\n",
    "  * **Telemetry**: The operating conditions of a machine e.g. data collected from sensors.\n",
    "  * **Failure**: The failure history of a machine or component within the machine.\n",
    "\n",
    "We first load these files. Since the Azure Blob storage account name and account key are not passed between notebooks, you'll need to provide those here again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Azure blob storage details here \n",
    "#ACCOUNT_NAME = \"\"\n",
    "\n",
    "# You can find the account key under the _Access Keys_ link in the \n",
    "# [Azure Portal](portal.azure.com) page for your Azure storage container.\n",
    "#ACCOUNT_KEY = \"\"\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# The data from the Data Aquisition note book is stored in the dataingestion container.\n",
    "CONTAINER_NAME = \"dataingestion\"\n",
    "\n",
    "# The data constructed in this notebook will be stored in the featureengineering container\n",
    "STORAGE_CONTAINER_NAME = \"featureengineering\"\n",
    "\n",
    "# Connect to your blob service     \n",
    "az_blob_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)\n",
    "\n",
    "# We will store each of these data sets in blob storage in an \n",
    "# Azure Storage Container on your Azure subscription.\n",
    "# See https://github.com/Azure/ViennaDocs/blob/master/Documentation/UsingBlobForStorage.md\n",
    "# for details.\n",
    "\n",
    "# These file names detail which blob each file is stored under. \n",
    "MACH_DATA = 'machines_files.parquet'\n",
    "MAINT_DATA = 'maint_files.parquet'\n",
    "ERROR_DATA = 'errors_files.parquet'\n",
    "TELEMETRY_DATA = 'telemetry_files.parquet'\n",
    "FAILURE_DATA = 'failure_files.parquet'\n",
    "\n",
    "# These file names detail the local paths where we store the data results.\n",
    "MACH_LOCAL_DIRECT = 'dataingestion_mach_result.parquet'\n",
    "ERROR_LOCAL_DIRECT = 'dataingestion_err_result.parquet'\n",
    "MAINT_LOCAL_DIRECT = 'dataingestion_maint_result.parquet'\n",
    "TELEMETRY_LOCAL_DIRECT = 'dataingestion_tel_result.parquet'\n",
    "FAILURES_LOCAL_DIRECT = 'dataingestion_fail_result.parquet'\n",
    "\n",
    "# This is the final data file.\n",
    "FEATURES_LOCAL_DIRECT = 'featureengineering_files.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machines data set\n",
    "\n",
    "Now, we load the machines data set from your Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>model2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>model4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>model3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>model3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>model2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID   model  age\n",
       "0          1  model2   18\n",
       "1          2  model4    7\n",
       "2          3  model3    8\n",
       "3          4  model3    7\n",
       "4          5  model2    2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a local path  to store the data.\n",
    "if not os.path.exists(MACH_LOCAL_DIRECT):\n",
    "    os.makedirs(MACH_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# Connect to blob storage container\n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if MACH_DATA in blob.name:\n",
    "        local_file = os.path.join(MACH_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "# Read in the data\n",
    "machines = spark.read.parquet(MACH_LOCAL_DIRECT)\n",
    "\n",
    "print(machines.count())\n",
    "machines.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors data set\n",
    "\n",
    "Load the errors data set from your Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35901\n",
      "root\n",
      " |-- datetime: string (nullable = true)\n",
      " |-- machineID: long (nullable = true)\n",
      " |-- errorID: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>errorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-08 19:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-09 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-08 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-07 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-07 06:00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID errorID\n",
       "0  2015-04-08 19:00:00        251  error3\n",
       "1  2015-06-09 06:00:00        251  error1\n",
       "2  2015-08-08 06:00:00        251  error4\n",
       "3  2015-09-07 06:00:00        251  error2\n",
       "4  2015-09-07 06:00:00        251  error3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(ERROR_LOCAL_DIRECT):\n",
    "    os.makedirs(ERROR_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# Connect to blob storage container\n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if ERROR_DATA in blob.name:\n",
    "        local_file = os.path.join(ERROR_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "# Read in the data\n",
    "errors = spark.read.parquet(ERROR_LOCAL_DIRECT)\n",
    "\n",
    "print(errors.count())\n",
    "errors.printSchema()\n",
    "errors.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenance data set\n",
    "\n",
    "Load the maintenance data set from your Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97776\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-19 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-18 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-05 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-20 06:00:00</td>\n",
       "      <td>252</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID   comp\n",
       "0  2015-01-04 06:00:00        252  comp1\n",
       "1  2015-01-19 06:00:00        252  comp4\n",
       "2  2015-02-18 06:00:00        252  comp3\n",
       "3  2015-03-05 06:00:00        252  comp2\n",
       "4  2015-03-20 06:00:00        252  comp1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a local path  to store the data.\n",
    "if not os.path.exists(MAINT_LOCAL_DIRECT):\n",
    "    os.makedirs(MAINT_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# Connect to blob storage container\n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if MAINT_DATA in blob.name:\n",
    "        local_file = os.path.join(MAINT_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "# Read in the data\n",
    "maint = spark.read.parquet(MAINT_LOCAL_DIRECT)\n",
    "\n",
    "print(maint.count())\n",
    "maint.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Telemetry\n",
    "\n",
    "Load the telemetry data set from your Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26283000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>volt</th>\n",
       "      <th>rotate</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-08 10:00:00</td>\n",
       "      <td>501</td>\n",
       "      <td>165.775142</td>\n",
       "      <td>456.014484</td>\n",
       "      <td>96.779707</td>\n",
       "      <td>40.200315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-08 11:00:00</td>\n",
       "      <td>501</td>\n",
       "      <td>167.694494</td>\n",
       "      <td>415.396525</td>\n",
       "      <td>106.346838</td>\n",
       "      <td>39.454320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-08 12:00:00</td>\n",
       "      <td>501</td>\n",
       "      <td>149.286911</td>\n",
       "      <td>549.794168</td>\n",
       "      <td>110.590462</td>\n",
       "      <td>46.649346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-08 13:00:00</td>\n",
       "      <td>501</td>\n",
       "      <td>164.315444</td>\n",
       "      <td>485.343432</td>\n",
       "      <td>102.644426</td>\n",
       "      <td>38.615502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08 14:00:00</td>\n",
       "      <td>501</td>\n",
       "      <td>178.789891</td>\n",
       "      <td>447.830204</td>\n",
       "      <td>100.238279</td>\n",
       "      <td>36.380291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID        volt      rotate    pressure  \\\n",
       "0  2015-01-08 10:00:00        501  165.775142  456.014484   96.779707   \n",
       "1  2015-01-08 11:00:00        501  167.694494  415.396525  106.346838   \n",
       "2  2015-01-08 12:00:00        501  149.286911  549.794168  110.590462   \n",
       "3  2015-01-08 13:00:00        501  164.315444  485.343432  102.644426   \n",
       "4  2015-01-08 14:00:00        501  178.789891  447.830204  100.238279   \n",
       "\n",
       "   vibration  \n",
       "0  40.200315  \n",
       "1  39.454320  \n",
       "2  46.649346  \n",
       "3  38.615502  \n",
       "4  36.380291  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a local path  to store the data.\n",
    "if not os.path.exists(TELEMETRY_LOCAL_DIRECT):\n",
    "    os.makedirs(TELEMETRY_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# Connect to blob storage container\n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if TELEMETRY_DATA in blob.name:\n",
    "        local_file = os.path.join(TELEMETRY_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "# Read in the data\n",
    "telemetry = spark.read.parquet(TELEMETRY_LOCAL_DIRECT)\n",
    "\n",
    "print(telemetry.count())\n",
    "telemetry.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failures data set\n",
    "\n",
    "Load the failures data set from your Azure blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6368\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-31 06:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-17 06:00:00</td>\n",
       "      <td>179</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-28 06:00:00</td>\n",
       "      <td>191</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-13 06:00:00</td>\n",
       "      <td>221</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-28 06:00:00</td>\n",
       "      <td>262</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID failure\n",
       "0  2015-07-31 06:00:00          7   comp1\n",
       "1  2015-02-17 06:00:00        179   comp4\n",
       "2  2015-12-28 06:00:00        191   comp1\n",
       "3  2015-06-13 06:00:00        221   comp2\n",
       "4  2015-06-28 06:00:00        262   comp2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a local path  to store the data.\n",
    "if not os.path.exists(FAILURES_LOCAL_DIRECT):\n",
    "    os.makedirs(FAILURES_LOCAL_DIRECT)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if FAILURE_DATA in blob.name:\n",
    "        local_file = os.path.join(FAILURES_LOCAL_DIRECT, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "failures = spark.read.parquet(FAILURES_LOCAL_DIRECT).dropDuplicates(['machineID', 'datetime'])\n",
    "\n",
    "print(failures.count())\n",
    "failures.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering \n",
    "\n",
    "Our feature engineering will combine the different data sources together to create a single data set of features (variables) that can be used to infer a machines's health condition over time. The ultimate goal is to generate a single record for each time unit within each asset. The record combines features and labels to be fed into the machine learning algorithm.\n",
    "\n",
    "Predictive maintenance take historical data, marked with a timestamp, to predict current health of a component and the probability of failure within some future window of time. These problems can be characterised as a _classification method_ involving _time series_ data. Time series, since we want to use historical observations to predict what will happen in the future. Classification, because we classify the future as having a probability of failure.\n",
    "\n",
    "### Lag features\n",
    "\n",
    "There are many ways of creating features from the time series data. We start by dividing the duration of data collection into time units where each record belongs to a single point in time for each asset. The measurement unit for is in fact arbitrary. Time can be in seconds, minutes, hours, days, or months, or it can be measured in cycles, miles or transactions. The measurement choice is typically specific to the use case domain.\n",
    "\n",
    "Additionally, the time unit does not have to be the same as the frequency of data collection. For example, if temperature values were being collected every 10 seconds, picking a time unit of 10 seconds for analysis may inflate the number of examples without providing any additional information if the temperature changes slowly. A better strategy may be to average the temperature over a longer time horizon which might better capture variations that contribute to the target outcome.\n",
    "\n",
    "Once we set the frequency of observations, we want to look for trends within measures, over time, in order to predict performance degradation, which we would like to connect to how likely a component will fail. We create features for these trends within each record using time lags over previous observations to check for these performance changes. The lag window size $W$ is a hyper parameter that we can optimize. The following figures indicate a _rolling aggregate window_ strategy for averaging a measure $t_i$ over a window $W = 3$ previous observations.\n",
    "\n",
    "![Rolling windows](../images/rolling-aggregate-features.png)\n",
    "\n",
    "We are note constrained to averages, we can roll aggregates over counts, average, the standard deviation, outliers based on standard deviations, CUSUM measures, minimum and maximum values for the window. \n",
    "\n",
    "We could also use a tumbling window approach, if we were interested in a different time window measure than the frequncy of the observations. For example, we might have obersvations evert 6 or 12 hours, but want to create features aligned on a day or week basis.  \n",
    "![Tumbling windows](../images/tumbling-aggregate-features.png)\n",
    "\n",
    "In the following sections, we will build our features using only a rolling strategy to demonstrate the process. We align our data, and then build features along those normalized observations times. We start with the telemetry data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telemetry features\n",
    "\n",
    "Because the telemetry data set is the largest time series data we have, we start feature engineering here. The telemetry data has 8761000 hourly observations for out 1000 machines. We can improve the model performance by aligning our data by aggregating average sensor measures on a tumbling 12 hour window. In this case we replace the raw data with the tumbling window data, reducing the sensor data to 731000 observations. This will directly reduce the computaton time required to do the feature engineering, labeling and modeling required for our solution.    \n",
    "\n",
    "Once we have the reduced data, we set up our lag features by compute rolling aggregate measures such as mean, standard deviation, minimum, maximum, etc. to represent the short term history of the telemetry over time. \n",
    "\n",
    "The following code blocks alignes the data on 12 hour observations and calculates a rolling mean and standard deviation of the telemetry data over the last 12, 24 and 36 hour lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling mean and standard deviation\n",
    "# Temporary storage for rolling means\n",
    "tel_mean = telemetry\n",
    "\n",
    "# Which features are we interested in telemetry data set\n",
    "rolling_features = ['volt','rotate', 'pressure', 'vibration']\n",
    "      \n",
    "# n hours = n * 3600 seconds  \n",
    "time_val = 12 * 3600\n",
    "\n",
    "# Choose the time_val hour timestamps to align the data\n",
    "# dt_truncated looks at the column named \"datetime\" in the current data set.\n",
    "# remember that Spark is lazy... this doesn't execute until it is in a withColumn statement.\n",
    "dt_truncated = ((round(unix_timestamp(col(\"datetime\")) / time_val) * time_val).cast(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>...</th>\n",
       "      <th>pressure_rollingstd_12</th>\n",
       "      <th>vibration_rollingstd_12</th>\n",
       "      <th>volt_rollingstd_24</th>\n",
       "      <th>rotate_rollingstd_24</th>\n",
       "      <th>pressure_rollingstd_24</th>\n",
       "      <th>vibration_rollingstd_24</th>\n",
       "      <th>volt_rollingstd_36</th>\n",
       "      <th>rotate_rollingstd_36</th>\n",
       "      <th>pressure_rollingstd_36</th>\n",
       "      <th>vibration_rollingstd_36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-04-02 12:00:00</td>\n",
       "      <td>169.504358</td>\n",
       "      <td>458.080859</td>\n",
       "      <td>98.853100</td>\n",
       "      <td>40.206282</td>\n",
       "      <td>172.276693</td>\n",
       "      <td>453.914465</td>\n",
       "      <td>100.149237</td>\n",
       "      <td>39.388604</td>\n",
       "      <td>...</td>\n",
       "      <td>1.967764</td>\n",
       "      <td>1.450408</td>\n",
       "      <td>2.574380</td>\n",
       "      <td>7.842277</td>\n",
       "      <td>0.697507</td>\n",
       "      <td>0.642817</td>\n",
       "      <td>2.029878</td>\n",
       "      <td>4.257344</td>\n",
       "      <td>0.469016</td>\n",
       "      <td>0.696241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-12 00:00:00</td>\n",
       "      <td>174.752893</td>\n",
       "      <td>447.869796</td>\n",
       "      <td>99.104835</td>\n",
       "      <td>37.912595</td>\n",
       "      <td>173.328100</td>\n",
       "      <td>451.021134</td>\n",
       "      <td>99.197901</td>\n",
       "      <td>39.176060</td>\n",
       "      <td>...</td>\n",
       "      <td>3.686390</td>\n",
       "      <td>1.586467</td>\n",
       "      <td>3.872359</td>\n",
       "      <td>4.502588</td>\n",
       "      <td>2.144001</td>\n",
       "      <td>0.972561</td>\n",
       "      <td>2.842595</td>\n",
       "      <td>2.876937</td>\n",
       "      <td>1.613863</td>\n",
       "      <td>0.869366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-26 12:00:00</td>\n",
       "      <td>164.973477</td>\n",
       "      <td>440.217397</td>\n",
       "      <td>94.586757</td>\n",
       "      <td>41.848857</td>\n",
       "      <td>167.125874</td>\n",
       "      <td>448.332605</td>\n",
       "      <td>95.745427</td>\n",
       "      <td>41.503863</td>\n",
       "      <td>...</td>\n",
       "      <td>3.237066</td>\n",
       "      <td>0.969911</td>\n",
       "      <td>1.599882</td>\n",
       "      <td>5.677769</td>\n",
       "      <td>1.470616</td>\n",
       "      <td>0.448602</td>\n",
       "      <td>1.340792</td>\n",
       "      <td>2.718405</td>\n",
       "      <td>0.902162</td>\n",
       "      <td>0.404061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-08-04 00:00:00</td>\n",
       "      <td>167.911567</td>\n",
       "      <td>492.569736</td>\n",
       "      <td>100.299672</td>\n",
       "      <td>39.586859</td>\n",
       "      <td>168.887626</td>\n",
       "      <td>485.283536</td>\n",
       "      <td>99.435951</td>\n",
       "      <td>39.745648</td>\n",
       "      <td>...</td>\n",
       "      <td>3.018383</td>\n",
       "      <td>1.784219</td>\n",
       "      <td>1.965474</td>\n",
       "      <td>5.006491</td>\n",
       "      <td>1.181980</td>\n",
       "      <td>0.767992</td>\n",
       "      <td>1.343253</td>\n",
       "      <td>2.728301</td>\n",
       "      <td>0.960705</td>\n",
       "      <td>0.679509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-08-23 12:00:00</td>\n",
       "      <td>170.813463</td>\n",
       "      <td>433.742572</td>\n",
       "      <td>101.722879</td>\n",
       "      <td>40.204782</td>\n",
       "      <td>170.125657</td>\n",
       "      <td>425.172196</td>\n",
       "      <td>101.880923</td>\n",
       "      <td>39.585259</td>\n",
       "      <td>...</td>\n",
       "      <td>1.992043</td>\n",
       "      <td>1.527793</td>\n",
       "      <td>2.245183</td>\n",
       "      <td>3.576078</td>\n",
       "      <td>1.881253</td>\n",
       "      <td>0.712531</td>\n",
       "      <td>1.665154</td>\n",
       "      <td>2.154706</td>\n",
       "      <td>1.607367</td>\n",
       "      <td>0.347801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-17 00:00:00</td>\n",
       "      <td>166.746403</td>\n",
       "      <td>461.177019</td>\n",
       "      <td>99.965307</td>\n",
       "      <td>39.030648</td>\n",
       "      <td>168.473344</td>\n",
       "      <td>457.179697</td>\n",
       "      <td>99.010242</td>\n",
       "      <td>39.161199</td>\n",
       "      <td>...</td>\n",
       "      <td>2.795527</td>\n",
       "      <td>1.483904</td>\n",
       "      <td>2.241567</td>\n",
       "      <td>5.203382</td>\n",
       "      <td>1.844869</td>\n",
       "      <td>1.125516</td>\n",
       "      <td>0.974139</td>\n",
       "      <td>5.938996</td>\n",
       "      <td>0.894611</td>\n",
       "      <td>0.760292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-16 12:00:00</td>\n",
       "      <td>162.764982</td>\n",
       "      <td>467.345254</td>\n",
       "      <td>93.235051</td>\n",
       "      <td>40.631218</td>\n",
       "      <td>165.212582</td>\n",
       "      <td>462.714226</td>\n",
       "      <td>94.687890</td>\n",
       "      <td>41.285949</td>\n",
       "      <td>...</td>\n",
       "      <td>2.040776</td>\n",
       "      <td>1.726990</td>\n",
       "      <td>2.210824</td>\n",
       "      <td>11.000059</td>\n",
       "      <td>0.922132</td>\n",
       "      <td>0.853953</td>\n",
       "      <td>2.718721</td>\n",
       "      <td>6.540091</td>\n",
       "      <td>0.939278</td>\n",
       "      <td>0.673975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-30 12:00:00</td>\n",
       "      <td>172.185544</td>\n",
       "      <td>456.572562</td>\n",
       "      <td>99.934121</td>\n",
       "      <td>50.627328</td>\n",
       "      <td>172.254541</td>\n",
       "      <td>458.164872</td>\n",
       "      <td>100.384868</td>\n",
       "      <td>48.665114</td>\n",
       "      <td>...</td>\n",
       "      <td>2.907054</td>\n",
       "      <td>2.345860</td>\n",
       "      <td>0.792869</td>\n",
       "      <td>16.982184</td>\n",
       "      <td>1.709924</td>\n",
       "      <td>1.898605</td>\n",
       "      <td>0.914669</td>\n",
       "      <td>12.779607</td>\n",
       "      <td>1.622618</td>\n",
       "      <td>1.136515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-31 12:00:00</td>\n",
       "      <td>170.453718</td>\n",
       "      <td>382.620105</td>\n",
       "      <td>97.386500</td>\n",
       "      <td>51.473313</td>\n",
       "      <td>172.445912</td>\n",
       "      <td>397.881664</td>\n",
       "      <td>96.610581</td>\n",
       "      <td>51.898352</td>\n",
       "      <td>...</td>\n",
       "      <td>3.420846</td>\n",
       "      <td>1.257551</td>\n",
       "      <td>1.762591</td>\n",
       "      <td>13.068849</td>\n",
       "      <td>1.415854</td>\n",
       "      <td>0.326730</td>\n",
       "      <td>2.653562</td>\n",
       "      <td>13.276990</td>\n",
       "      <td>1.098551</td>\n",
       "      <td>0.344981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-11 12:00:00</td>\n",
       "      <td>172.870633</td>\n",
       "      <td>454.444227</td>\n",
       "      <td>100.745268</td>\n",
       "      <td>39.492203</td>\n",
       "      <td>173.957241</td>\n",
       "      <td>453.429312</td>\n",
       "      <td>101.286805</td>\n",
       "      <td>39.202149</td>\n",
       "      <td>...</td>\n",
       "      <td>2.544891</td>\n",
       "      <td>1.393332</td>\n",
       "      <td>3.237451</td>\n",
       "      <td>8.295104</td>\n",
       "      <td>1.528917</td>\n",
       "      <td>0.728565</td>\n",
       "      <td>2.093676</td>\n",
       "      <td>6.602655</td>\n",
       "      <td>1.369296</td>\n",
       "      <td>0.431994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n",
       "0          1 2015-04-02 12:00:00           169.504358             458.080859   \n",
       "1          1 2015-05-12 00:00:00           174.752893             447.869796   \n",
       "2          1 2015-07-26 12:00:00           164.973477             440.217397   \n",
       "3          1 2015-08-04 00:00:00           167.911567             492.569736   \n",
       "4          1 2015-08-23 12:00:00           170.813463             433.742572   \n",
       "5          1 2015-12-17 00:00:00           166.746403             461.177019   \n",
       "6          1 2015-02-16 12:00:00           162.764982             467.345254   \n",
       "7          1 2015-10-30 12:00:00           172.185544             456.572562   \n",
       "8          1 2015-10-31 12:00:00           170.453718             382.620105   \n",
       "9          1 2015-12-11 12:00:00           172.870633             454.444227   \n",
       "\n",
       "   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n",
       "0                98.853100                 40.206282           172.276693   \n",
       "1                99.104835                 37.912595           173.328100   \n",
       "2                94.586757                 41.848857           167.125874   \n",
       "3               100.299672                 39.586859           168.887626   \n",
       "4               101.722879                 40.204782           170.125657   \n",
       "5                99.965307                 39.030648           168.473344   \n",
       "6                93.235051                 40.631218           165.212582   \n",
       "7                99.934121                 50.627328           172.254541   \n",
       "8                97.386500                 51.473313           172.445912   \n",
       "9               100.745268                 39.492203           173.957241   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             453.914465               100.149237                 39.388604   \n",
       "1             451.021134                99.197901                 39.176060   \n",
       "2             448.332605                95.745427                 41.503863   \n",
       "3             485.283536                99.435951                 39.745648   \n",
       "4             425.172196               101.880923                 39.585259   \n",
       "5             457.179697                99.010242                 39.161199   \n",
       "6             462.714226                94.687890                 41.285949   \n",
       "7             458.164872               100.384868                 48.665114   \n",
       "8             397.881664                96.610581                 51.898352   \n",
       "9             453.429312               101.286805                 39.202149   \n",
       "\n",
       "            ...             pressure_rollingstd_12  vibration_rollingstd_12  \\\n",
       "0           ...                           1.967764                 1.450408   \n",
       "1           ...                           3.686390                 1.586467   \n",
       "2           ...                           3.237066                 0.969911   \n",
       "3           ...                           3.018383                 1.784219   \n",
       "4           ...                           1.992043                 1.527793   \n",
       "5           ...                           2.795527                 1.483904   \n",
       "6           ...                           2.040776                 1.726990   \n",
       "7           ...                           2.907054                 2.345860   \n",
       "8           ...                           3.420846                 1.257551   \n",
       "9           ...                           2.544891                 1.393332   \n",
       "\n",
       "   volt_rollingstd_24  rotate_rollingstd_24  pressure_rollingstd_24  \\\n",
       "0            2.574380              7.842277                0.697507   \n",
       "1            3.872359              4.502588                2.144001   \n",
       "2            1.599882              5.677769                1.470616   \n",
       "3            1.965474              5.006491                1.181980   \n",
       "4            2.245183              3.576078                1.881253   \n",
       "5            2.241567              5.203382                1.844869   \n",
       "6            2.210824             11.000059                0.922132   \n",
       "7            0.792869             16.982184                1.709924   \n",
       "8            1.762591             13.068849                1.415854   \n",
       "9            3.237451              8.295104                1.528917   \n",
       "\n",
       "   vibration_rollingstd_24  volt_rollingstd_36  rotate_rollingstd_36  \\\n",
       "0                 0.642817            2.029878              4.257344   \n",
       "1                 0.972561            2.842595              2.876937   \n",
       "2                 0.448602            1.340792              2.718405   \n",
       "3                 0.767992            1.343253              2.728301   \n",
       "4                 0.712531            1.665154              2.154706   \n",
       "5                 1.125516            0.974139              5.938996   \n",
       "6                 0.853953            2.718721              6.540091   \n",
       "7                 1.898605            0.914669             12.779607   \n",
       "8                 0.326730            2.653562             13.276990   \n",
       "9                 0.728565            2.093676              6.602655   \n",
       "\n",
       "   pressure_rollingstd_36  vibration_rollingstd_36  \n",
       "0                0.469016                 0.696241  \n",
       "1                1.613863                 0.869366  \n",
       "2                0.902162                 0.404061  \n",
       "3                0.960705                 0.679509  \n",
       "4                1.607367                 0.347801  \n",
       "5                0.894611                 0.760292  \n",
       "6                0.939278                 0.673975  \n",
       "7                1.622618                 1.136515  \n",
       "8                1.098551                 0.344981  \n",
       "9                1.369296                 0.431994  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We choose windows for our rolling windows 12hrs, 24 hrs and 36 hrs\n",
    "lags = [12, 24, 36]\n",
    "\n",
    "# align the data\n",
    "for lag_n in lags:\n",
    "    wSpec = Window.partitionBy('machineID').orderBy('datetime').rowsBetween(1-lag_n, 0)\n",
    "    for col_name in rolling_features:\n",
    "        tel_mean = tel_mean.withColumn(col_name+'_rollingmean_'+str(lag_n), \n",
    "                                       F.avg(col(col_name)).over(wSpec))\n",
    "        tel_mean = tel_mean.withColumn(col_name+'_rollingstd_'+str(lag_n), \n",
    "                                       F.stddev(col(col_name)).over(wSpec))\n",
    "\n",
    "# Calculate lag values...\n",
    "telemetry_feat = (tel_mean.withColumn(\"dt_truncated\", dt_truncated)\n",
    "                  .drop('volt', 'rotate', 'pressure', 'vibration')\n",
    "                  .fillna(0)\n",
    "                  .groupBy(\"machineID\",\"dt_truncated\")\n",
    "                  .agg(F.mean('volt_rollingmean_12').alias('volt_rollingmean_12'),\n",
    "                       F.mean('rotate_rollingmean_12').alias('rotate_rollingmean_12'), \n",
    "                       F.mean('pressure_rollingmean_12').alias('pressure_rollingmean_12'), \n",
    "                       F.mean('vibration_rollingmean_12').alias('vibration_rollingmean_12'), \n",
    "                       F.mean('volt_rollingmean_24').alias('volt_rollingmean_24'),\n",
    "                       F.mean('rotate_rollingmean_24').alias('rotate_rollingmean_24'), \n",
    "                       F.mean('pressure_rollingmean_24').alias('pressure_rollingmean_24'), \n",
    "                       F.mean('vibration_rollingmean_24').alias('vibration_rollingmean_24'),\n",
    "                       F.mean('volt_rollingmean_36').alias('volt_rollingmean_36'),\n",
    "                       F.mean('vibration_rollingmean_36').alias('vibration_rollingmean_36'),\n",
    "                       F.mean('rotate_rollingmean_36').alias('rotate_rollingmean_36'), \n",
    "                       F.mean('pressure_rollingmean_36').alias('pressure_rollingmean_36'), \n",
    "                       F.stddev('volt_rollingstd_12').alias('volt_rollingstd_12'),\n",
    "                       F.stddev('rotate_rollingstd_12').alias('rotate_rollingstd_12'), \n",
    "                       F.stddev('pressure_rollingstd_12').alias('pressure_rollingstd_12'), \n",
    "                       F.stddev('vibration_rollingstd_12').alias('vibration_rollingstd_12'), \n",
    "                       F.stddev('volt_rollingstd_24').alias('volt_rollingstd_24'),\n",
    "                       F.stddev('rotate_rollingstd_24').alias('rotate_rollingstd_24'), \n",
    "                       F.stddev('pressure_rollingstd_24').alias('pressure_rollingstd_24'), \n",
    "                       F.stddev('vibration_rollingstd_24').alias('vibration_rollingstd_24'),\n",
    "                       F.stddev('volt_rollingstd_36').alias('volt_rollingstd_36'),\n",
    "                       F.stddev('rotate_rollingstd_36').alias('rotate_rollingstd_36'), \n",
    "                       F.stddev('pressure_rollingstd_36').alias('pressure_rollingstd_36'), \n",
    "                       F.stddev('vibration_rollingstd_36').alias('vibration_rollingstd_36'), ))\n",
    "\n",
    "print(telemetry_feat.count())\n",
    "telemetry_feat.where((col(\"machineID\") == 1)).limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors features\n",
    "\n",
    "Like telemetry data, errors come with timestamps. An important difference is that the error IDs are categorical values and should not be averaged over time intervals like the telemetry measurements. Instead, we count the number of errors of each type within a lag window. \n",
    "\n",
    "Again, we align the error counts data by tumbling over the 12 hour window using a join with telemetry data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>error1sum_rollingmean_24</th>\n",
       "      <th>error2sum_rollingmean_24</th>\n",
       "      <th>error3sum_rollingmean_24</th>\n",
       "      <th>error4sum_rollingmean_24</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-04-27 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-06-28 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-08-11 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-03-04 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-04-06 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-05-14 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-06-20 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-10-16 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>474</td>\n",
       "      <td>2015-05-29 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>474</td>\n",
       "      <td>2015-09-15 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        dt_truncated  error1sum_rollingmean_24  \\\n",
       "0         26 2015-04-27 12:00:00                       0.0   \n",
       "1         26 2015-06-28 12:00:00                       0.0   \n",
       "2         26 2015-08-11 00:00:00                       0.0   \n",
       "3         29 2015-03-04 00:00:00                       0.0   \n",
       "4         29 2015-04-06 00:00:00                       0.0   \n",
       "5         29 2015-05-14 12:00:00                       0.0   \n",
       "6         29 2015-06-20 12:00:00                       0.0   \n",
       "7         29 2015-10-16 00:00:00                       0.0   \n",
       "8        474 2015-05-29 12:00:00                       0.0   \n",
       "9        474 2015-09-15 00:00:00                       0.0   \n",
       "\n",
       "   error2sum_rollingmean_24  error3sum_rollingmean_24  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "5                       0.0                       0.0   \n",
       "6                       0.0                       0.0   \n",
       "7                       0.0                       0.0   \n",
       "8                       0.0                       0.0   \n",
       "9                       0.0                       0.0   \n",
       "\n",
       "   error4sum_rollingmean_24  error5sum_rollingmean_24  \n",
       "0                       0.0                       0.0  \n",
       "1                       0.0                       0.0  \n",
       "2                       0.0                       0.0  \n",
       "3                       0.0                       0.0  \n",
       "4                       0.0                       0.0  \n",
       "5                       0.0                       0.0  \n",
       "6                       0.0                       0.0  \n",
       "7                       0.0                       0.0  \n",
       "8                       0.0                       0.0  \n",
       "9                       0.0                       0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column for each errorID \n",
    "error_ind = (errors.groupBy(\"machineID\",\"datetime\",\"errorID\").pivot('errorID')\n",
    "             .agg(F.count('machineID').alias('dummy')).drop('errorID').fillna(0)\n",
    "             .groupBy(\"machineID\",\"datetime\")\n",
    "             .agg(F.sum('error1').alias('error1sum'), \n",
    "                  F.sum('error2').alias('error2sum'), \n",
    "                  F.sum('error3').alias('error3sum'), \n",
    "                  F.sum('error4').alias('error4sum'), \n",
    "                  F.sum('error5').alias('error5sum')))\n",
    "\n",
    "# join the telemetry data with errors\n",
    "error_count = (telemetry.join(error_ind, \n",
    "                              ((telemetry['machineID'] == error_ind['machineID']) \n",
    "                               & (telemetry['datetime'] == error_ind['datetime'])), \"left\")\n",
    "               .drop('volt', 'rotate', 'pressure', 'vibration')\n",
    "               .drop(error_ind.machineID).drop(error_ind.datetime)\n",
    "               .fillna(0))\n",
    "\n",
    "error_features = ['error1sum','error2sum', 'error3sum', 'error4sum', 'error5sum']\n",
    "\n",
    "wSpec = Window.partitionBy('machineID').orderBy('datetime').rowsBetween(1-24, 0)\n",
    "for col_name in error_features:\n",
    "    # We're only interested in the erros in the previous 24 hours.\n",
    "    error_count = error_count.withColumn(col_name+'_rollingmean_24', \n",
    "                                         F.avg(col(col_name)).over(wSpec))\n",
    "\n",
    "error_feat = (error_count.withColumn(\"dt_truncated\", dt_truncated)\n",
    "              .drop('error1sum', 'error2sum', 'error3sum', 'error4sum', 'error5sum').fillna(0)\n",
    "              .groupBy(\"machineID\",\"dt_truncated\")\n",
    "              .agg(F.mean('error1sum_rollingmean_24').alias('error1sum_rollingmean_24'), \n",
    "                   F.mean('error2sum_rollingmean_24').alias('error2sum_rollingmean_24'), \n",
    "                   F.mean('error3sum_rollingmean_24').alias('error3sum_rollingmean_24'), \n",
    "                   F.mean('error4sum_rollingmean_24').alias('error4sum_rollingmean_24'), \n",
    "                   F.mean('error5sum_rollingmean_24').alias('error5sum_rollingmean_24')))\n",
    "\n",
    "print(error_feat.count())\n",
    "error_feat.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days since last replacement from maintenance \n",
    "\n",
    "A crucial data set in this example is the use of maintenance records, which contain the information regarding component replacement. Possible features from this data set can be the number of replacements of each component over time or to calculate how long it has been since a component has been replaced. Replacement time is expected to correlate better with component failures since the longer a component is used, the more degradation would be expected.\n",
    "\n",
    "As a side note, creating lagging features from maintenance data is not straight forward. This type of ad-hoc feature engineering is very common in predictive maintenance as domain knowledge plays a crucial role in understanding the predictors of a failure problem. In the following code blocks, the days since last component replacement are calculated for each component from the maintenance data. We start by counting the component replacements for the set of machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>datetime_maint</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191</td>\n",
       "      <td>2015-12-28 06:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>567</td>\n",
       "      <td>2015-09-17 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301</td>\n",
       "      <td>2015-04-04 06:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>852</td>\n",
       "      <td>2015-06-14 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>942</td>\n",
       "      <td>2015-09-23 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66</td>\n",
       "      <td>2015-09-30 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>370</td>\n",
       "      <td>2015-07-22 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>512</td>\n",
       "      <td>2015-05-03 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>427</td>\n",
       "      <td>2015-06-15 06:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>490</td>\n",
       "      <td>2015-10-26 06:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID       datetime_maint  comp1sum  comp2sum  comp3sum  comp4sum\n",
       "0        191  2015-12-28 06:00:00         3         0         0         0\n",
       "1        567  2015-09-17 06:00:00         0         0         0         3\n",
       "2        301  2015-04-04 06:00:00         3         3         0         0\n",
       "3        852  2015-06-14 06:00:00         0         0         3         0\n",
       "4        942  2015-09-23 06:00:00         0         0         3         3\n",
       "5         66  2015-09-30 06:00:00         0         0         3         0\n",
       "6        370  2015-07-22 06:00:00         0         3         0         3\n",
       "7        512  2015-05-03 06:00:00         0         0         3         0\n",
       "8        427  2015-06-15 06:00:00         0         0         3         3\n",
       "9        490  2015-10-26 06:00:00         3         3         0         0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column for each component replacement\n",
    "maint_replace = (maint.groupBy(\"machineID\",\"datetime\",\"comp\").pivot('comp')\n",
    "                 .agg(F.count('machineID').alias('dummy')).fillna(0)\n",
    "                 .groupBy(\"machineID\",\"datetime\")\n",
    "                 .agg(F.sum('comp1').alias('comp1sum'), \n",
    "                      F.sum('comp2').alias('comp2sum'), \n",
    "                      F.sum('comp3').alias('comp3sum'),\n",
    "                      F.sum('comp4').alias('comp4sum')))\n",
    "\n",
    "maint_replace = maint_replace.withColumnRenamed('datetime','datetime_maint')\n",
    "\n",
    "print(maint_replace.count())\n",
    "maint_replace.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacement features are then created by tracking the number of days between each component replacement. We'll repeat these calculations for each of the four components and join them together into a maintenance feature table.\n",
    "\n",
    "First component number 1 (`comp1`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>datetime_tel</th>\n",
       "      <th>sincelastcomp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [machineID, datetime_tel, sincelastcomp1]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to align the component information on telemetry features timestamps.\n",
    "telemetry_times = (telemetry_feat.select(telemetry_feat.machineID, telemetry_feat.dt_truncated)\n",
    "                   .withColumnRenamed('dt_truncated','datetime_tel'))\n",
    "\n",
    "# Grab component 1 records\n",
    "maint_comp1 = (maint_replace.where(col(\"comp1sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "               .drop('comp2sum', 'comp3sum', 'comp4sum'))\n",
    "\n",
    "# Within each machine, get the last replacement date for each timepoint\n",
    "maint_tel_comp1 = (telemetry_times.join(maint_comp1, \n",
    "                                        ((telemetry_times ['machineID']== maint_comp1['machineID']) \n",
    "                                         & (telemetry_times ['datetime_tel'] > maint_comp1['datetime_maint']) \n",
    "                                         & ( maint_comp1['comp1sum'] == '1')))\n",
    "                   .drop(maint_comp1.machineID))\n",
    "\n",
    "# Calculate the number of days between replacements\n",
    "comp1 = (maint_tel_comp1.withColumn(\"sincelastcomp1\", \n",
    "                                    datediff(maint_tel_comp1.datetime_tel, maint_tel_comp1.datetime_maint))\n",
    "         .drop(maint_tel_comp1.datetime_maint).drop(maint_tel_comp1.comp1sum))\n",
    "\n",
    "print(comp1.count())\n",
    "comp1.filter(comp1.machineID == '625').orderBy(comp1.datetime_tel).limit(20).toPandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then component 2 (`comp2`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>datetime_tel</th>\n",
       "      <th>sincelastcomp2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [machineID, datetime_tel, sincelastcomp2]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab component 2 records\n",
    "maint_comp2 = (maint_replace.where(col(\"comp2sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "               .drop('comp1sum', 'comp3sum', 'comp4sum'))\n",
    "\n",
    "# Within each machine, get the last replacement date for each timepoint\n",
    "maint_tel_comp2 = (telemetry_times.join(maint_comp2, \n",
    "                                        ((telemetry_times ['machineID']== maint_comp2['machineID']) \n",
    "                                         & (telemetry_times ['datetime_tel'] > maint_comp2['datetime_maint']) \n",
    "                                         & ( maint_comp2['comp2sum'] == '1')))\n",
    "                   .drop(maint_comp2.machineID))\n",
    "\n",
    "# Calculate the number of days between replacements\n",
    "comp2 = (maint_tel_comp2.withColumn(\"sincelastcomp2\", \n",
    "                                    datediff(maint_tel_comp2.datetime_tel, maint_tel_comp2.datetime_maint))\n",
    "         .drop(maint_tel_comp2.datetime_maint).drop(maint_tel_comp2.comp2sum))\n",
    "\n",
    "print(comp2.count())\n",
    "comp2.filter(comp2.machineID == '625').orderBy(comp2.datetime_tel).limit(5).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then component 3 (`comp3`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>datetime_tel</th>\n",
       "      <th>sincelastcomp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [machineID, datetime_tel, sincelastcomp3]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab component 3 records\n",
    "maint_comp3 = (maint_replace.where(col(\"comp3sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "               .drop('comp1sum', 'comp2sum', 'comp4sum'))\n",
    "\n",
    "# Within each machine, get the last replacement date for each timepoint\n",
    "maint_tel_comp3 = (telemetry_times.join(maint_comp3, ((telemetry_times ['machineID']==maint_comp3['machineID']) \n",
    "                                                      & (telemetry_times ['datetime_tel'] > maint_comp3['datetime_maint']) \n",
    "                                                      & ( maint_comp3['comp3sum'] == '1')))\n",
    "                   .drop(maint_comp3.machineID))\n",
    "\n",
    "# Calculate the number of days between replacements\n",
    "comp3 = (maint_tel_comp3.withColumn(\"sincelastcomp3\", \n",
    "                                    datediff(maint_tel_comp3.datetime_tel, maint_tel_comp3.datetime_maint))\n",
    "         .drop(maint_tel_comp3.datetime_maint).drop(maint_tel_comp3.comp3sum))\n",
    "\n",
    "\n",
    "print(comp3.count())\n",
    "comp3.filter(comp3.machineID == '625').orderBy(comp3.datetime_tel).limit(5).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and component 4 (`comp4`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>datetime_tel</th>\n",
       "      <th>sincelastcomp4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [machineID, datetime_tel, sincelastcomp4]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab component 4 records\n",
    "maint_comp4 = (maint_replace.where(col(\"comp4sum\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
    "               .drop('comp1sum', 'comp2sum', 'comp3sum'))\n",
    "\n",
    "# Within each machine, get the last replacement date for each timepoint\n",
    "maint_tel_comp4 = telemetry_times.join(maint_comp4, ((telemetry_times['machineID']==maint_comp4['machineID']) \n",
    "                                                     & (telemetry_times['datetime_tel'] > maint_comp4['datetime_maint']) \n",
    "                                                     & (maint_comp4['comp4sum'] == '1'))).drop(maint_comp4.machineID)\n",
    "\n",
    "# Calculate the number of days between replacements\n",
    "comp4 = (maint_tel_comp4.withColumn(\"sincelastcomp4\", \n",
    "                                    datediff(maint_tel_comp4.datetime_tel, maint_tel_comp4.datetime_maint))\n",
    "         .drop(maint_tel_comp4.datetime_maint).drop(maint_tel_comp4.comp4sum))\n",
    "\n",
    "print(comp4.count())\n",
    "comp4.filter(comp4.machineID == '625').orderBy(comp4.datetime_tel).limit(5).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we join the four component replacement tables together. Once joined, align the data by tumbling the average across 12 hour observation windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [machineID, dt_truncated, comp1sum, comp2sum, comp3sum, comp4sum]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join component 3 and 4\n",
    "comp3_4 = (comp3.join(comp4, ((comp3['machineID'] == comp4['machineID']) \n",
    "                              & (comp3['datetime_tel'] == comp4['datetime_tel'])), \"left\")\n",
    "           .drop(comp4.machineID).drop(comp4.datetime_tel))\n",
    "\n",
    "# Join component 2 to 3 and 4\n",
    "comp2_3_4 = (comp2.join(comp3_4, ((comp2['machineID'] == comp3_4['machineID']) \n",
    "                                  & (comp2['datetime_tel'] == comp3_4['datetime_tel'])), \"left\")\n",
    "             .drop(comp3_4.machineID).drop(comp3_4.datetime_tel))\n",
    "\n",
    "# Join component 1 to 2, 3 and 4\n",
    "comps_feat = (comp1.join(comp2_3_4, ((comp1['machineID'] == comp2_3_4['machineID']) \n",
    "                                      & (comp1['datetime_tel'] == comp2_3_4['datetime_tel'])), \"left\")\n",
    "               .drop(comp2_3_4.machineID).drop(comp2_3_4.datetime_tel)\n",
    "               .groupBy(\"machineID\", \"datetime_tel\")\n",
    "               .agg(F.max('sincelastcomp1').alias('sincelastcomp1'), \n",
    "                    F.max('sincelastcomp2').alias('sincelastcomp2'), \n",
    "                    F.max('sincelastcomp3').alias('sincelastcomp3'), \n",
    "                    F.max('sincelastcomp4').alias('sincelastcomp4'))\n",
    "               .fillna(0))\n",
    "\n",
    "# Choose the time_val hour timestamps to align the data\n",
    "dt_truncated = ((round(unix_timestamp(col(\"datetime_tel\")) / time_val) * time_val).cast(\"timestamp\"))\n",
    "\n",
    "# Collect data\n",
    "maint_feat = (comps_feat.withColumn(\"dt_truncated\", dt_truncated)\n",
    "              .groupBy(\"machineID\",\"dt_truncated\")\n",
    "              .agg(F.mean('sincelastcomp1').alias('comp1sum'), \n",
    "                   F.mean('sincelastcomp2').alias('comp2sum'), \n",
    "                   F.mean('sincelastcomp3').alias('comp3sum'), \n",
    "                   F.mean('sincelastcomp4').alias('comp4sum')))\n",
    "\n",
    "print(maint_feat.count())\n",
    "maint_feat.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine features\n",
    "\n",
    "The machine features capture specifics of the individuals. These can be used without further modification since it include descriptive information about the type of each machine and its age (number of years in service). If the age information had been recorded as a \"first use date\" for each machine, a transformation would have been necessary to turn those into a numeric values indicating the years in service.\n",
    "\n",
    "We do need to create a set of dummy features, a set of boolean variables, to indicate the model of the machine. This can either be done manually, or using a _one-hot encoding_ step. We use the one-hot encoding for demonstration purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "      <th>model_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>model2</td>\n",
       "      <td>18</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>model4</td>\n",
       "      <td>7</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>model3</td>\n",
       "      <td>8</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>model3</td>\n",
       "      <td>7</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>model2</td>\n",
       "      <td>2</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>model3</td>\n",
       "      <td>7</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>model4</td>\n",
       "      <td>20</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>model3</td>\n",
       "      <td>16</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>model1</td>\n",
       "      <td>7</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>model1</td>\n",
       "      <td>10</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID   model  age    model_encoded\n",
       "0          1  model2   18  (0.0, 0.0, 1.0)\n",
       "1          2  model4    7  (0.0, 1.0, 0.0)\n",
       "2          3  model3    8  (1.0, 0.0, 0.0)\n",
       "3          4  model3    7  (1.0, 0.0, 0.0)\n",
       "4          5  model2    2  (0.0, 0.0, 1.0)\n",
       "5          6  model3    7  (1.0, 0.0, 0.0)\n",
       "6          7  model4   20  (0.0, 1.0, 0.0)\n",
       "7          8  model3   16  (1.0, 0.0, 0.0)\n",
       "8          9  model1    7  (0.0, 0.0, 0.0)\n",
       "9         10  model1   10  (0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding of the variable model, basically creates a set of dummy boolean variables\n",
    "catVarNames = ['model']  \n",
    "sIndexers = [StringIndexer(inputCol=x, outputCol=x + '_indexed') for x in catVarNames]\n",
    "machines_cat = Pipeline(stages=sIndexers).fit(machines).transform(machines)\n",
    "\n",
    "# one-hot encode\n",
    "ohEncoders = [OneHotEncoder(inputCol=x + '_indexed', outputCol=x + '_encoded')\n",
    "              for x in catVarNames]\n",
    "\n",
    "ohPipelineModel = Pipeline(stages=ohEncoders).fit(machines_cat)\n",
    "machines_cat = ohPipelineModel.transform(machines_cat)\n",
    "\n",
    "drop_list = [col_n for col_n in machines_cat.columns if 'indexed' in col_n]\n",
    "\n",
    "machines_feat = machines_cat.select([column for column in machines_cat.columns if column not in drop_list])\n",
    "\n",
    "print(machines_feat.count())\n",
    "machines_feat.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging feature data\n",
    "\n",
    "Next, we merge the telemetry, maintenance, machine and error feature data sets into a large feature data set. Since most of the data has already been aligned on the 12 hour observation period, we can merge with a simple join strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>...</th>\n",
       "      <th>error3sum_rollingmean_24</th>\n",
       "      <th>error4sum_rollingmean_24</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "      <th>model_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-01 12:00:00</td>\n",
       "      <td>167.726562</td>\n",
       "      <td>457.023539</td>\n",
       "      <td>97.671510</td>\n",
       "      <td>43.288417</td>\n",
       "      <td>168.903523</td>\n",
       "      <td>454.765815</td>\n",
       "      <td>97.818506</td>\n",
       "      <td>44.520524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>model3</td>\n",
       "      <td>13</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-01 12:00:00</td>\n",
       "      <td>167.726562</td>\n",
       "      <td>457.023539</td>\n",
       "      <td>97.671510</td>\n",
       "      <td>43.288417</td>\n",
       "      <td>168.903523</td>\n",
       "      <td>454.765815</td>\n",
       "      <td>97.818506</td>\n",
       "      <td>44.520524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>model3</td>\n",
       "      <td>13</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-01 12:00:00</td>\n",
       "      <td>167.726562</td>\n",
       "      <td>457.023539</td>\n",
       "      <td>97.671510</td>\n",
       "      <td>43.288417</td>\n",
       "      <td>168.903523</td>\n",
       "      <td>454.765815</td>\n",
       "      <td>97.818506</td>\n",
       "      <td>44.520524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>model3</td>\n",
       "      <td>13</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>167.669833</td>\n",
       "      <td>446.268601</td>\n",
       "      <td>94.255945</td>\n",
       "      <td>43.192112</td>\n",
       "      <td>166.942467</td>\n",
       "      <td>453.117332</td>\n",
       "      <td>95.029026</td>\n",
       "      <td>42.636115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>model3</td>\n",
       "      <td>13</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>167.669833</td>\n",
       "      <td>446.268601</td>\n",
       "      <td>94.255945</td>\n",
       "      <td>43.192112</td>\n",
       "      <td>166.942467</td>\n",
       "      <td>453.117332</td>\n",
       "      <td>95.029026</td>\n",
       "      <td>42.636115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>model3</td>\n",
       "      <td>13</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 00:00:00</td>\n",
       "      <td>167.669833</td>\n",
       "      <td>446.268601</td>\n",
       "      <td>94.255945</td>\n",
       "      <td>43.192112</td>\n",
       "      <td>166.942467</td>\n",
       "      <td>453.117332</td>\n",
       "      <td>95.029026</td>\n",
       "      <td>42.636115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>model3</td>\n",
       "      <td>13</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 12:00:00</td>\n",
       "      <td>172.036832</td>\n",
       "      <td>466.794278</td>\n",
       "      <td>99.847922</td>\n",
       "      <td>40.537832</td>\n",
       "      <td>169.998556</td>\n",
       "      <td>458.611466</td>\n",
       "      <td>98.524816</td>\n",
       "      <td>40.788719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>model3</td>\n",
       "      <td>13</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 12:00:00</td>\n",
       "      <td>172.036832</td>\n",
       "      <td>466.794278</td>\n",
       "      <td>99.847922</td>\n",
       "      <td>40.537832</td>\n",
       "      <td>169.998556</td>\n",
       "      <td>458.611466</td>\n",
       "      <td>98.524816</td>\n",
       "      <td>40.788719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>model3</td>\n",
       "      <td>13</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-02 12:00:00</td>\n",
       "      <td>172.036832</td>\n",
       "      <td>466.794278</td>\n",
       "      <td>99.847922</td>\n",
       "      <td>40.537832</td>\n",
       "      <td>169.998556</td>\n",
       "      <td>458.611466</td>\n",
       "      <td>98.524816</td>\n",
       "      <td>40.788719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>model3</td>\n",
       "      <td>13</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>625</td>\n",
       "      <td>2015-01-03 00:00:00</td>\n",
       "      <td>170.684677</td>\n",
       "      <td>455.829133</td>\n",
       "      <td>102.043135</td>\n",
       "      <td>40.259893</td>\n",
       "      <td>171.506318</td>\n",
       "      <td>459.226593</td>\n",
       "      <td>102.043397</td>\n",
       "      <td>40.308199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>model3</td>\n",
       "      <td>13</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n",
       "0        625 2015-01-01 12:00:00           167.726562             457.023539   \n",
       "1        625 2015-01-01 12:00:00           167.726562             457.023539   \n",
       "2        625 2015-01-01 12:00:00           167.726562             457.023539   \n",
       "3        625 2015-01-02 00:00:00           167.669833             446.268601   \n",
       "4        625 2015-01-02 00:00:00           167.669833             446.268601   \n",
       "5        625 2015-01-02 00:00:00           167.669833             446.268601   \n",
       "6        625 2015-01-02 12:00:00           172.036832             466.794278   \n",
       "7        625 2015-01-02 12:00:00           172.036832             466.794278   \n",
       "8        625 2015-01-02 12:00:00           172.036832             466.794278   \n",
       "9        625 2015-01-03 00:00:00           170.684677             455.829133   \n",
       "\n",
       "   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n",
       "0                97.671510                 43.288417           168.903523   \n",
       "1                97.671510                 43.288417           168.903523   \n",
       "2                97.671510                 43.288417           168.903523   \n",
       "3                94.255945                 43.192112           166.942467   \n",
       "4                94.255945                 43.192112           166.942467   \n",
       "5                94.255945                 43.192112           166.942467   \n",
       "6                99.847922                 40.537832           169.998556   \n",
       "7                99.847922                 40.537832           169.998556   \n",
       "8                99.847922                 40.537832           169.998556   \n",
       "9               102.043135                 40.259893           171.506318   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             454.765815                97.818506                 44.520524   \n",
       "1             454.765815                97.818506                 44.520524   \n",
       "2             454.765815                97.818506                 44.520524   \n",
       "3             453.117332                95.029026                 42.636115   \n",
       "4             453.117332                95.029026                 42.636115   \n",
       "5             453.117332                95.029026                 42.636115   \n",
       "6             458.611466                98.524816                 40.788719   \n",
       "7             458.611466                98.524816                 40.788719   \n",
       "8             458.611466                98.524816                 40.788719   \n",
       "9             459.226593               102.043397                 40.308199   \n",
       "\n",
       "        ...         error3sum_rollingmean_24  error4sum_rollingmean_24  \\\n",
       "0       ...                              0.0                       0.0   \n",
       "1       ...                              0.0                       0.0   \n",
       "2       ...                              0.0                       0.0   \n",
       "3       ...                              0.0                       0.0   \n",
       "4       ...                              0.0                       0.0   \n",
       "5       ...                              0.0                       0.0   \n",
       "6       ...                              0.0                       0.0   \n",
       "7       ...                              0.0                       0.0   \n",
       "8       ...                              0.0                       0.0   \n",
       "9       ...                              0.0                       0.0   \n",
       "\n",
       "   error5sum_rollingmean_24  comp1sum  comp2sum  comp3sum  comp4sum   model  \\\n",
       "0                       0.0      None      None      None      None  model3   \n",
       "1                       0.0      None      None      None      None  model3   \n",
       "2                       0.0      None      None      None      None  model3   \n",
       "3                       0.0      None      None      None      None  model3   \n",
       "4                       0.0      None      None      None      None  model3   \n",
       "5                       0.0      None      None      None      None  model3   \n",
       "6                       0.0      None      None      None      None  model3   \n",
       "7                       0.0      None      None      None      None  model3   \n",
       "8                       0.0      None      None      None      None  model3   \n",
       "9                       0.0      None      None      None      None  model3   \n",
       "\n",
       "   age    model_encoded  \n",
       "0   13  (1.0, 0.0, 0.0)  \n",
       "1   13  (1.0, 0.0, 0.0)  \n",
       "2   13  (1.0, 0.0, 0.0)  \n",
       "3   13  (1.0, 0.0, 0.0)  \n",
       "4   13  (1.0, 0.0, 0.0)  \n",
       "5   13  (1.0, 0.0, 0.0)  \n",
       "6   13  (1.0, 0.0, 0.0)  \n",
       "7   13  (1.0, 0.0, 0.0)  \n",
       "8   13  (1.0, 0.0, 0.0)  \n",
       "9   13  (1.0, 0.0, 0.0)  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join error features with component maintenance features\n",
    "error_maint = (error_feat.join(maint_feat, \n",
    "                               ((error_feat['machineID'] == maint_feat['machineID']) \n",
    "                                & (error_feat['dt_truncated'] == maint_feat['dt_truncated'])), \"left\")\n",
    "               .drop(maint_feat.machineID).drop(maint_feat.dt_truncated))\n",
    "\n",
    "# now join that with machines features\n",
    "error_maint_feat = (error_maint.join(machines_feat, \n",
    "                                     ((error_maint['machineID'] == machines_feat['machineID'])), \"left\")\n",
    "                    .drop(machines_feat.machineID))\n",
    "\n",
    "# Clean up some unecessary columns\n",
    "error_maint_feat = error_maint_feat.select([c for c in error_maint_feat.columns if c not in \n",
    "                                            {'error1sum', 'error2sum', 'error3sum', 'error4sum', 'error5sum'}])\n",
    "\n",
    "# join telemetry with error/maint/machine features to create final feature matrix\n",
    "final_feat = (telemetry_feat.join(error_maint_feat, \n",
    "                                  ((telemetry_feat['machineID'] == error_maint_feat['machineID']) \n",
    "                                   & (telemetry_feat['dt_truncated'] == error_maint_feat['dt_truncated'])), \"left\")\n",
    "              .drop(error_maint_feat.machineID).drop(error_maint_feat.dt_truncated))\n",
    "\n",
    "print(final_feat.count())\n",
    "final_feat.filter(final_feat.machineID == '625').orderBy(final_feat.dt_truncated).limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label construction\n",
    "\n",
    "Predictive maintenance is supervised learning. To train a model to predict failures requires examples of failures, and the time series of observations leading up to those failures. Additionally, the model needs examples of periods of healthy operation in order to discern the difference between the two states. The classification between these states is typically a boolean label (healthy vs failed).\n",
    "\n",
    "Once we have the healthy vs. failure states, the predictive maintenance approach is only useful if the method will give some advanced warning of an impending failure. To accomplish this _prior warning_ criteria, we slightly modify the label definition from a _failure event_ which occurs at a specific moment in time, to a longer window of _failure event occurs within this window_. The window length is defined by the business criteria. Is knowing a failure will occur within 12 hours, enough time to prevent the failure from happening? Is 24 hours, or 2 weeks? The ability of the model to accurately predict an impending failure is dependent sizing this window. If the failure signal is short, longer windows will not help, and can actually degrade, the potential performance.   \n",
    "\n",
    "To acheive the redefinition of failure to _about to fail_, we over label failure events, labeling all observations within the failure warning window as failed. The prediction problem then becomes estimating the probability of failure within this window. \n",
    "\n",
    "![over label](../images/labelling-for-binary-classification.png)\n",
    "\n",
    "For this example scenerio, we estimate the probability that a machine will fail in the near future due to a failure of a certain component. More specifically, the goal is to compute the probability that a machine will fail in the next 7 days due to a component failure (component 1, 2, 3, or 4). \n",
    "\n",
    "Below, a categorical failure feature is created to serve as the label. All records within a 24 hour window before a failure of component 1 have failure=\"comp1\", and so on for components 2, 3, and 4; all records not within 7 days of a component failure have failure=\"none\".\n",
    "\n",
    "The first step is to alighn the failure data to the feature observation time points (every 12 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6368\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>failure</th>\n",
       "      <th>dt_truncated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>comp1</td>\n",
       "      <td>2015-07-31 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "      <td>comp4</td>\n",
       "      <td>2015-02-17 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191</td>\n",
       "      <td>comp1</td>\n",
       "      <td>2015-12-28 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>comp2</td>\n",
       "      <td>2015-06-13 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262</td>\n",
       "      <td>comp2</td>\n",
       "      <td>2015-06-28 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>288</td>\n",
       "      <td>comp2</td>\n",
       "      <td>2015-10-19 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>322</td>\n",
       "      <td>comp3</td>\n",
       "      <td>2015-11-27 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>346</td>\n",
       "      <td>comp4</td>\n",
       "      <td>2015-02-17 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>352</td>\n",
       "      <td>comp1</td>\n",
       "      <td>2015-11-27 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>382</td>\n",
       "      <td>comp3</td>\n",
       "      <td>2015-11-22 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID failure        dt_truncated\n",
       "0          7   comp1 2015-07-31 12:00:00\n",
       "1        179   comp4 2015-02-17 12:00:00\n",
       "2        191   comp1 2015-12-28 12:00:00\n",
       "3        221   comp2 2015-06-13 12:00:00\n",
       "4        262   comp2 2015-06-28 12:00:00\n",
       "5        288   comp2 2015-10-19 12:00:00\n",
       "6        322   comp3 2015-11-27 12:00:00\n",
       "7        346   comp4 2015-02-17 12:00:00\n",
       "8        352   comp1 2015-11-27 12:00:00\n",
       "9        382   comp3 2015-11-22 12:00:00"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_truncated = ((round(unix_timestamp(col(\"datetime\")) / time_val) * time_val).cast(\"timestamp\"))\n",
    "\n",
    "fail_diff = (failures.withColumn(\"dt_truncated\", dt_truncated)\n",
    "             .drop(failures.datetime))\n",
    "\n",
    "print(fail_diff.count())\n",
    "fail_diff.limit(10).toPandas().head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert the labels from text to numeric values. In the end, this will transform the problem from boolean of 'healthy'/'impending failure' to a multiclass 'healthy'/'component `n` impending failure'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193000\n"
     ]
    }
   ],
   "source": [
    "# map the failure data to final feature matrix\n",
    "labeled_features = (final_feat.join(fail_diff, \n",
    "                                    ((final_feat['machineID'] == fail_diff['machineID']) \n",
    "                                     & (final_feat['dt_truncated'] == fail_diff['dt_truncated'])), \"left\")\n",
    "                    .drop(fail_diff.machineID).drop(fail_diff.dt_truncated)\n",
    "                    .withColumn('failure', F.when(col('failure') == \"comp1\", 1.0).otherwise(col('failure')))\n",
    "                    .withColumn('failure', F.when(col('failure') == \"comp2\", 2.0).otherwise(col('failure')))\n",
    "                    .withColumn('failure', F.when(col('failure') == \"comp3\", 3.0).otherwise(col('failure')))\n",
    "                    .withColumn('failure', F.when(col('failure') == \"comp4\", 4.0).otherwise(col('failure'))))\n",
    "\n",
    "labeled_features = (labeled_features.withColumn(\"failure\", \n",
    "                                                labeled_features.failure.cast(DoubleType()))\n",
    "                    .fillna(0))\n",
    "\n",
    "print(labeled_features.count())\n",
    "labeled_features.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify we have assigned the component failure records correctly, we count the failure classes within the feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2173896\n",
       "2.0       7401\n",
       "1.0       5658\n",
       "4.0       3309\n",
       "3.0       2736\n",
       "Name: failure, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the frequency of each component failure \n",
    "df = labeled_features.select(labeled_features.failure).toPandas()\n",
    "df['failure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To now, we have labels as _failure events_. To convert to _impending failure_, we over label over the previous 7 days as _failed_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>...</th>\n",
       "      <th>error5sum_rollingmean_24</th>\n",
       "      <th>comp1sum</th>\n",
       "      <th>comp2sum</th>\n",
       "      <th>comp3sum</th>\n",
       "      <th>comp4sum</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "      <th>model_encoded</th>\n",
       "      <th>failure</th>\n",
       "      <th>label_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01 12:00:00</td>\n",
       "      <td>156.344085</td>\n",
       "      <td>468.057739</td>\n",
       "      <td>124.013028</td>\n",
       "      <td>42.178511</td>\n",
       "      <td>162.025185</td>\n",
       "      <td>475.175738</td>\n",
       "      <td>128.051943</td>\n",
       "      <td>42.778459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01 12:00:00</td>\n",
       "      <td>156.344085</td>\n",
       "      <td>468.057739</td>\n",
       "      <td>124.013028</td>\n",
       "      <td>42.178511</td>\n",
       "      <td>162.025185</td>\n",
       "      <td>475.175738</td>\n",
       "      <td>128.051943</td>\n",
       "      <td>42.778459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01 12:00:00</td>\n",
       "      <td>156.344085</td>\n",
       "      <td>468.057739</td>\n",
       "      <td>124.013028</td>\n",
       "      <td>42.178511</td>\n",
       "      <td>162.025185</td>\n",
       "      <td>475.175738</td>\n",
       "      <td>128.051943</td>\n",
       "      <td>42.778459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>163.950541</td>\n",
       "      <td>463.526286</td>\n",
       "      <td>126.531407</td>\n",
       "      <td>42.349105</td>\n",
       "      <td>164.387412</td>\n",
       "      <td>458.076924</td>\n",
       "      <td>125.984343</td>\n",
       "      <td>41.609348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>163.950541</td>\n",
       "      <td>463.526286</td>\n",
       "      <td>126.531407</td>\n",
       "      <td>42.349105</td>\n",
       "      <td>164.387412</td>\n",
       "      <td>458.076924</td>\n",
       "      <td>125.984343</td>\n",
       "      <td>41.609348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>163.950541</td>\n",
       "      <td>463.526286</td>\n",
       "      <td>126.531407</td>\n",
       "      <td>42.349105</td>\n",
       "      <td>164.387412</td>\n",
       "      <td>458.076924</td>\n",
       "      <td>125.984343</td>\n",
       "      <td>41.609348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-31 12:00:00</td>\n",
       "      <td>170.101450</td>\n",
       "      <td>444.259746</td>\n",
       "      <td>124.232805</td>\n",
       "      <td>40.276008</td>\n",
       "      <td>169.520645</td>\n",
       "      <td>447.900337</td>\n",
       "      <td>121.007364</td>\n",
       "      <td>40.509231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-31 12:00:00</td>\n",
       "      <td>170.101450</td>\n",
       "      <td>444.259746</td>\n",
       "      <td>124.232805</td>\n",
       "      <td>40.276008</td>\n",
       "      <td>169.520645</td>\n",
       "      <td>447.900337</td>\n",
       "      <td>121.007364</td>\n",
       "      <td>40.509231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-31 12:00:00</td>\n",
       "      <td>170.101450</td>\n",
       "      <td>444.259746</td>\n",
       "      <td>124.232805</td>\n",
       "      <td>40.276008</td>\n",
       "      <td>169.520645</td>\n",
       "      <td>447.900337</td>\n",
       "      <td>121.007364</td>\n",
       "      <td>40.509231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "      <td>165.952772</td>\n",
       "      <td>453.459165</td>\n",
       "      <td>98.901505</td>\n",
       "      <td>40.877614</td>\n",
       "      <td>165.591482</td>\n",
       "      <td>445.886418</td>\n",
       "      <td>97.494281</td>\n",
       "      <td>41.431352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model3</td>\n",
       "      <td>3</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID        dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n",
       "0         26 2016-01-01 12:00:00           156.344085             468.057739   \n",
       "1         26 2016-01-01 12:00:00           156.344085             468.057739   \n",
       "2         26 2016-01-01 12:00:00           156.344085             468.057739   \n",
       "3         26 2016-01-01 00:00:00           163.950541             463.526286   \n",
       "4         26 2016-01-01 00:00:00           163.950541             463.526286   \n",
       "5         26 2016-01-01 00:00:00           163.950541             463.526286   \n",
       "6         26 2015-12-31 12:00:00           170.101450             444.259746   \n",
       "7         26 2015-12-31 12:00:00           170.101450             444.259746   \n",
       "8         26 2015-12-31 12:00:00           170.101450             444.259746   \n",
       "9         26 2015-12-31 00:00:00           165.952772             453.459165   \n",
       "\n",
       "   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n",
       "0               124.013028                 42.178511           162.025185   \n",
       "1               124.013028                 42.178511           162.025185   \n",
       "2               124.013028                 42.178511           162.025185   \n",
       "3               126.531407                 42.349105           164.387412   \n",
       "4               126.531407                 42.349105           164.387412   \n",
       "5               126.531407                 42.349105           164.387412   \n",
       "6               124.232805                 40.276008           169.520645   \n",
       "7               124.232805                 40.276008           169.520645   \n",
       "8               124.232805                 40.276008           169.520645   \n",
       "9                98.901505                 40.877614           165.591482   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             475.175738               128.051943                 42.778459   \n",
       "1             475.175738               128.051943                 42.778459   \n",
       "2             475.175738               128.051943                 42.778459   \n",
       "3             458.076924               125.984343                 41.609348   \n",
       "4             458.076924               125.984343                 41.609348   \n",
       "5             458.076924               125.984343                 41.609348   \n",
       "6             447.900337               121.007364                 40.509231   \n",
       "7             447.900337               121.007364                 40.509231   \n",
       "8             447.900337               121.007364                 40.509231   \n",
       "9             445.886418                97.494281                 41.431352   \n",
       "\n",
       "    ...     error5sum_rollingmean_24  comp1sum  comp2sum  comp3sum  comp4sum  \\\n",
       "0   ...                          0.0       0.0       0.0       0.0       0.0   \n",
       "1   ...                          0.0       0.0       0.0       0.0       0.0   \n",
       "2   ...                          0.0       0.0       0.0       0.0       0.0   \n",
       "3   ...                          0.0       0.0       0.0       0.0       0.0   \n",
       "4   ...                          0.0       0.0       0.0       0.0       0.0   \n",
       "5   ...                          0.0       0.0       0.0       0.0       0.0   \n",
       "6   ...                          0.0       0.0       0.0       0.0       0.0   \n",
       "7   ...                          0.0       0.0       0.0       0.0       0.0   \n",
       "8   ...                          0.0       0.0       0.0       0.0       0.0   \n",
       "9   ...                          0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "    model  age    model_encoded  failure  label_e  \n",
       "0  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n",
       "1  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n",
       "2  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n",
       "3  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n",
       "4  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n",
       "5  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n",
       "6  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n",
       "7  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n",
       "8  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n",
       "9  model3    3  (1.0, 0.0, 0.0)      0.0      0.0  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lag values to manually backfill label (bfill =7)\n",
    "my_window = Window.partitionBy('machineID').orderBy(labeled_features.dt_truncated.desc())\n",
    "\n",
    "# Create the previous 7 days \n",
    "labeled_features = (labeled_features.withColumn(\"prev_value1\", \n",
    "                                                F.lag(labeled_features.failure).\n",
    "                                                over(my_window)).fillna(0))\n",
    "labeled_features = (labeled_features.withColumn(\"prev_value2\", \n",
    "                                                F.lag(labeled_features.prev_value1).\n",
    "                                                over(my_window)).fillna(0))\n",
    "labeled_features = (labeled_features.withColumn(\"prev_value3\", \n",
    "                                                F.lag(labeled_features.prev_value2).\n",
    "                                                over(my_window)).fillna(0))\n",
    "labeled_features = (labeled_features.withColumn(\"prev_value4\", \n",
    "                                                F.lag(labeled_features.prev_value3).\n",
    "                                                over(my_window)).fillna(0)) \n",
    "labeled_features = (labeled_features.withColumn(\"prev_value5\", \n",
    "                                                F.lag(labeled_features.prev_value4).\n",
    "                                                over(my_window)).fillna(0)) \n",
    "labeled_features = (labeled_features.withColumn(\"prev_value6\", \n",
    "                                                F.lag(labeled_features.prev_value5).\n",
    "                                                over(my_window)).fillna(0))\n",
    "labeled_features = (labeled_features.withColumn(\"prev_value7\", \n",
    "                                                F.lag(labeled_features.prev_value6).\n",
    "                                                over(my_window)).fillna(0))\n",
    "\n",
    "# Create a label features\n",
    "labeled_features = (labeled_features.withColumn('label', labeled_features.failure + \n",
    "                                                labeled_features.prev_value1 +\n",
    "                                                labeled_features.prev_value2 +\n",
    "                                                labeled_features.prev_value3 +\n",
    "                                                labeled_features.prev_value4 +\n",
    "                                                labeled_features.prev_value5 + \n",
    "                                                labeled_features.prev_value6 + \n",
    "                                                labeled_features.prev_value7))\n",
    "\n",
    "# Restrict the label to be on the range of 0:4, and remove extra columns\n",
    "labeled_features = (labeled_features.withColumn('label_e', F.when(col('label') > 4, 4.0)\n",
    "                                                .otherwise(col('label')))\n",
    "                    .drop(labeled_features.prev_value1).drop(labeled_features.prev_value2)\n",
    "                    .drop(labeled_features.prev_value3).drop(labeled_features.prev_value4)\n",
    "                    .drop(labeled_features.prev_value5).drop(labeled_features.prev_value6)\n",
    "                    .drop(labeled_features.prev_value7).drop(labeled_features.label))\n",
    "\n",
    "print(labeled_features.count())\n",
    "labeled_features.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the label construction, we plot a sample of four machines over the data set life time. We expect the labels to cluster for each component, since there are 7 day windows of \"fail\". We have omitted the healthy labels, as they are uninformative. Since the labels are actually classes, the plot as four distinct values on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (-9223363243238408942)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt_dta = (labeled_features.filter(labeled_features.label_e > 0)\n",
    "           .where(col(\"machineID\").isin({\"65\", \"558\", \"222\", \"965\"}))\n",
    "           .select(labeled_features.machineID, labeled_features.dt_truncated, labeled_features.label_e)\n",
    "           .toPandas())\n",
    "\n",
    "# format datetime field which comes in as string\n",
    "plt_dta['dt_truncated'] = pd.to_datetime(plt_dta['dt_truncated'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "plt_dta.label_e = plt_dta.label_e.astype(int)\n",
    "\n",
    "ggplot(aes(x=\"dt_truncated\", y=\"label_e\", color=\"label_e\"), plt_dta) +\\\n",
    "    geom_point()+\\\n",
    "    xlab(\"Date\") + ylab(\"Component Number\") +\\\n",
    "    scale_x_date(labels=date_format('%m-%d')) +\\\n",
    "    scale_color_brewer(type = 'seq', palette = 'BuGn') +\\\n",
    "    facet_grid('machineID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that most of the days are marked as healthy (label = 0 are omitted for plot performance, though the dates are still accurate). Each of the four machines have multiple failures over the course of the dataset. Each labeled failure includes the date of failure and the previous seven days, all are marked with the number indicating the component that failed. \n",
    "\n",
    "The goal of the model will be to predict when a failure will occur and which component will fail simultaneously. This will be a multiclass classification problem, though we could pivot the data to individually predict binary failure of a component instead of a machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Write the feature data to cloud storage\n",
    "\n",
    "Write the final labeled feature data as parquet file an Azure blob storage container. For technical details, see:\n",
    "https://github.com/Azure/ViennaDocs/blob/master/Documentation/UsingBlobForStorage.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-680206e9303a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Write labeled feature data to blob for use in the next notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlabeled_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'overwrite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFEATURES_LOCAL_DIRECT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Delete the old data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dsvm/tools/spark/current/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py36/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "Error in atexit._run_exitfuncs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/azureml/_history/utils/filesystem.py\", line 117, in get_abs_working_dir\n",
      "    cwd = self.file_system.getWorkingDirectory().toString()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1255, in __call__\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1079, in start\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "/dsvm/tools/spark/current/python/pyspark/context.py:422: RuntimeWarning: Unable to cleanly shutdown Spark JVM process. It is possible that the process has crashed, been killed or may also be in a zombie state.\n",
      "  RuntimeWarning\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/logging/__init__.py\", line 995, in emit\n",
      "    stream.write(msg)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 408, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 332, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 205, in schedule\n",
      "    f()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/iostream.py\", line 331, in _schedule_in_thread\n",
      "    self._io_loop.call_later(self.flush_interval, self._flush)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 638, in call_later\n",
      "    return self.call_at(self.time() + delay, callback, *args, **kwargs)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 145, in call_at\n",
      "    functools.partial(stack_context.wrap(callback), *args, **kwargs))\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 544, in call_later\n",
      "    timer = self.call_at(self.time() + delay, callback, *args)\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 554, in call_at\n",
      "    self._check_closed()\n",
      "  File \"/anaconda/envs/py36/lib/python3.6/asyncio/base_events.py\", line 358, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Call stack:\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "    _garbage_collect_object and _garbage_collect_object(cc, id))\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "    gateway_client.garbage_collect_object(target_id)\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "    \"\\ne\\n\")\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1078, in start\n",
      "    logger.exception(msg)\n",
      "Message: 'An error occurred while trying to connect to the Java server (127.0.0.1:38763)'\n",
      "Arguments: ()\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38763)\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dsvm/tools/spark/current/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    }
   ],
   "source": [
    "# Create a new container if necessary, otherwise you can use an existing container.\n",
    "# This command creates the container if it does not already exist. Else it does nothing.\n",
    "az_blob_service.create_container(STORAGE_CONTAINER_NAME, \n",
    "                                 fail_on_exist=False, \n",
    "                                 public_access=PublicAccess.Container)\n",
    "\n",
    "# Write labeled feature data to blob for use in the next notebook\n",
    "labeled_features.write.mode('overwrite').parquet(FEATURES_LOCAL_DIRECT)\n",
    "\n",
    "# Delete the old data.\n",
    "for blob in az_blob_service.list_blobs(STORAGE_CONTAINER_NAME):\n",
    "    if FEATURES_LOCAL_DIRECT in blob.name:\n",
    "        az_blob_service.delete_blob(STORAGE_CONTAINER_NAME, blob.name)\n",
    "\n",
    "# upload the entire folder into blob storage\n",
    "for name in glob.iglob(FEATURES_LOCAL_DIRECT + '/*'):\n",
    "    print(os.path.abspath(name))\n",
    "    az_blob_service.create_blob_from_path(STORAGE_CONTAINER_NAME, name, name)\n",
    "\n",
    "print(\"Feature engineering final dataset files saved!\")\n",
    "\n",
    "# Time the notebook execution. \n",
    "# This will only make sense if you \"Run All\" cells\n",
    "toc = time.time()\n",
    "print(\"Full run took %.2f minutes\" % ((toc - tic)/60))\n",
    "\n",
    "#logger.log(\"Feature Engineering Run time\", ((toc - tic)/60))\n",
    "run.log('Feature Engineering Run time', ((toc - tic)/60)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the run as completed \n",
    "run.complete() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The next step is to build and compare machine learning models using the feature data set we have just created. The `Code\\3_model_building.ipynb` notebook works through building a Decision Tree Classifier and a Random Forest Classifier using this data set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
